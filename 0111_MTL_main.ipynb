{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from utils.carbon import calculate_total_carbon\n",
    "from utils.cost import calculate_total_cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INPUTS\n",
    "TIME_HORIZONS= [2020, 2050, 2100]\n",
    "\n",
    "def get_csv_file_path(time_horizon: int) -> str:\n",
    "    file_name =f\"{time_horizon}_merged_simulation_results.csv\"\n",
    "    return f\"inputs/{file_name}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COLUMN LABELS\n",
    "TIME_HORIZON_LABEL = \"time_horizon\"\n",
    "SIMULATION_ID = \"simulation_id\"\n",
    "WINDOWS_U_FACTOR = 'windows_U_Factor'\n",
    "GROUND_FLOOR_THERMAL_RESISTANCE = \"groundfloor_thermal_resistance\"\n",
    "EXT_WALLS_THERMAL_RESISTANCE = \"ext_walls_thermal_resistance\"\n",
    "ROOF_THERMAL_RESISTANCE= \"roof_thermal_resistance\"\n",
    "ANNUAL_ENERGY_CONSUMPTION = \"annual_energy_consumption\"\n",
    "TOTAL_COST = \"total_cost\"\n",
    "TOTAL_CARBON_EMISSION = \"total_carbon_emission\"\n",
    "COMFORT_DAYS = \"comfort_days\"\n",
    "\n",
    "ELECTRICITY_BUILDING = \"Electricity:Building\"\n",
    "ELECTRICITY_FACILITY = \"Electricity:Facility\"\n",
    "GAS_CONSUMPTION = \"Gas Consumption\"\n",
    "INDOOR_TEMPERATURE = \"Zone Mean Air Temperature\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialize the dataframe with the inputs\n",
    "df_inputs = pd.DataFrame()\n",
    "df_inputs = pd.DataFrame(columns=[SIMULATION_ID, TIME_HORIZON_LABEL, WINDOWS_U_FACTOR, GROUND_FLOOR_THERMAL_RESISTANCE, EXT_WALLS_THERMAL_RESISTANCE, ROOF_THERMAL_RESISTANCE])\n",
    "\n",
    "# Initialize the dataframe with the outputs\n",
    "df_outputs = pd.DataFrame()\n",
    "df_outputs = pd.DataFrame(columns=[SIMULATION_ID, ANNUAL_ENERGY_CONSUMPTION, TOTAL_COST, TOTAL_CARBON_EMISSION, COMFORT_DAYS])\n",
    "\n",
    "for time_horizon in TIME_HORIZONS:\n",
    "    df = pd.read_csv(get_csv_file_path(time_horizon=time_horizon))\n",
    "\n",
    "    date_columns = [col for col in df.columns if col.startswith(f\"{str(TIME_HORIZONS[0])}-\")]\n",
    "\n",
    "    for simulation_id, group in df.groupby('Simulation ID'):\n",
    "\n",
    "        # Inputs\n",
    "        df_inputs = pd.concat([df_inputs,\n",
    "            pd.DataFrame({\n",
    "                SIMULATION_ID: [int(simulation_id)],\n",
    "                TIME_HORIZON_LABEL: [time_horizon],\n",
    "                WINDOWS_U_FACTOR : [group[WINDOWS_U_FACTOR].iloc[0]],\n",
    "                GROUND_FLOOR_THERMAL_RESISTANCE:[group[GROUND_FLOOR_THERMAL_RESISTANCE].iloc[0]],\n",
    "                EXT_WALLS_THERMAL_RESISTANCE:[group[EXT_WALLS_THERMAL_RESISTANCE].iloc[0]],\n",
    "                ROOF_THERMAL_RESISTANCE: [group[ROOF_THERMAL_RESISTANCE].iloc[0]]\n",
    "            })], ignore_index=True\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "        # Extract values\n",
    "        electricity_building = group[group['index'].str.contains(ELECTRICITY_BUILDING)].iloc[0]\n",
    "        electricity_facility = group[group['index'].str.contains(ELECTRICITY_FACILITY)].iloc[0] \n",
    "        gas_consumption = group[group['index'].str.contains(GAS_CONSUMPTION)].iloc[0] \n",
    "        indoor_temperature=group[group['index'].str.contains(INDOOR_TEMPERATURE)].iloc[0]\n",
    "\n",
    "\n",
    "        annual_energy_consumption = (electricity_building[date_columns].sum() + \n",
    "                                electricity_facility[date_columns].sum() + \n",
    "                                gas_consumption[date_columns].sum())/10**9\n",
    "        \n",
    "\n",
    "        window_U_factor= group[WINDOWS_U_FACTOR].iloc[0]\n",
    "        groundfloor_thermal_resistance=group[GROUND_FLOOR_THERMAL_RESISTANCE].iloc[0]\n",
    "        ext_walls_thermal_resistance=group[EXT_WALLS_THERMAL_RESISTANCE].iloc[0]\n",
    "        roof_thermal_resistance=group[ROOF_THERMAL_RESISTANCE].iloc[0]\n",
    "\n",
    "        total_cost = calculate_total_cost(\n",
    "            window_U_Factor=window_U_factor, \n",
    "            groundfloor_thermal_resistance=groundfloor_thermal_resistance,\n",
    "            ext_walls_thermal_resistance=ext_walls_thermal_resistance, \n",
    "            roof_thermal_resistance=roof_thermal_resistance\n",
    "            )\n",
    "        \n",
    "        comfort_days = min(len([item for item in indoor_temperature[date_columns].values if 18<item<24]),365)\n",
    "        \n",
    "        total_carbon_emission = calculate_total_carbon(        \n",
    "            window_U_Factor=window_U_factor, \n",
    "            groundfloor_thermal_resistance=groundfloor_thermal_resistance,\n",
    "            ext_walls_thermal_resistance=ext_walls_thermal_resistance, \n",
    "            roof_thermal_resistance=roof_thermal_resistance\n",
    "            )\n",
    "        \n",
    "\n",
    "        df_outputs = pd.concat([df_outputs,\n",
    "            pd.DataFrame({\n",
    "                SIMULATION_ID: [int(simulation_id)],\n",
    "                ANNUAL_ENERGY_CONSUMPTION : [annual_energy_consumption],\n",
    "                TOTAL_COST: [total_cost],\n",
    "                TOTAL_CARBON_EMISSION: [total_carbon_emission],\n",
    "                COMFORT_DAYS: [comfort_days]\n",
    "            })], ignore_index=True\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and Preprocess data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data = df_inputs[[TIME_HORIZON_LABEL, WINDOWS_U_FACTOR, GROUND_FLOOR_THERMAL_RESISTANCE, EXT_WALLS_THERMAL_RESISTANCE, ROOF_THERMAL_RESISTANCE]].values\n",
    "Y_data = df_outputs[[ANNUAL_ENERGY_CONSUMPTION, TOTAL_COST, TOTAL_CARBON_EMISSION, COMFORT_DAYS]].values\n",
    "scaler_X = StandardScaler()\n",
    "scaler_Y = StandardScaler()\n",
    "# Normalize the data \n",
    "X_data_normalized = scaler_X.fit_transform(X_data)\n",
    "Y_data_normalized = scaler_Y.fit_transform(Y_data)\n",
    "\n",
    "# Y_ORIGINAL = scaler_Y.inverse_transform(Y_data_normalized)\n",
    "\n",
    "\n",
    "# Split the dataset into training, testing and validation sets\n",
    "# Split data into train, validation, and test sets\n",
    "# Training Set: 70% of the original data.\n",
    "# Validation Set: 15% of the original data (from the temporary set).\n",
    "# Test Set: 15% of the original data (from the temporary set).\n",
    "\n",
    "train_inputs, temp_inputs, train_outputs, temp_outputs = train_test_split(\n",
    "    X_data_normalized, Y_data_normalized, test_size=0.3, random_state=42\n",
    ")\n",
    "val_inputs, test_inputs, val_outputs, test_outputs = train_test_split(\n",
    "    temp_inputs, temp_outputs, test_size=0.5, random_state=42\n",
    ")\n",
    "\n",
    "# Convert to torch tensors\n",
    "train_inputs = torch.tensor(train_inputs, dtype=torch.float32)\n",
    "train_outputs = torch.tensor(train_outputs, dtype=torch.float32)\n",
    "val_inputs = torch.tensor(val_inputs, dtype=torch.float32)\n",
    "val_outputs = torch.tensor(val_outputs, dtype=torch.float32)\n",
    "test_inputs = torch.tensor(test_inputs, dtype=torch.float32)\n",
    "test_outputs = torch.tensor(test_outputs, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiTaskModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MultiTaskModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(5, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3_energy = nn.Linear(64, 1)  # Annual Energy Consumption\n",
    "        self.fc3_cost = nn.Linear(64, 1)    # Total Cost\n",
    "        self.fc3_emission = nn.Linear(64, 1) # Total Carbon Emission\n",
    "        self.fc3_comfort = nn.Linear(64, 1)  # Comfort Days\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        energy = self.fc3_energy(x)\n",
    "        cost = self.fc3_cost(x)\n",
    "        emission = self.fc3_emission(x)\n",
    "        comfort = self.fc3_comfort(x)\n",
    "        return energy, cost, emission, comfort\n",
    "\n",
    "# Instantiate the model, define the loss function and the optimizer\n",
    "model = MultiTaskModel()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training the model\n",
    "num_epochs = 200\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Forward pass\n",
    "    outputs = model(train_inputs)\n",
    "    loss = sum(criterion(outputs[i], train_outputs[:, i:i+1]) for i in range(4))  # Total loss for all tasks\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    train_losses.append(loss.item())\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_outputs_pred = model(val_inputs)\n",
    "        val_loss = sum(criterion(val_outputs_pred[i], val_outputs[:, i:i+1]) for i in range(4))\n",
    "        val_losses.append(val_loss.item())\n",
    "\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f'Epoch [{epoch + 1}/{num_epochs}], Training Loss: {loss.item():.4f}, Validation Loss: {val_loss.item():.4f}')\n",
    "\n",
    "# Plotting training and validation losses\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(train_losses, label='Training Loss')\n",
    "plt.plot(val_losses, label='Validation Loss')\n",
    "plt.title('Training and Validation Losses')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing the model\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_outputs_pred = model(test_inputs)\n",
    "\n",
    "# Inverse transform to get original scale\n",
    "Y_test_inverse = scaler_Y.inverse_transform(test_outputs.numpy())\n",
    "Y_test_pred_inverse = scaler_Y.inverse_transform(torch.cat(test_outputs_pred, dim=1).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate percentage error\n",
    "percentage_error = np.abs((Y_test_pred_inverse - Y_test_inverse) / Y_test_inverse) * 100\n",
    "\n",
    "fig, axs = plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "# Define labels for outputs\n",
    "outputs_labels = ['Annual Energy Consumption', 'Total Cost', 'Total Carbon Emission', 'Comfort Days']\n",
    "\n",
    "# Predicted vs Actual scatter plots\n",
    "for i in range(4):\n",
    "    axs[i // 2, i % 2].scatter(Y_test_inverse[:, i], Y_test_pred_inverse[:, i])\n",
    "    axs[i // 2, i % 2].plot([Y_test_inverse[:, i].min(), Y_test_inverse[:, i].max()],\n",
    "                             [Y_test_inverse[:, i].min(), Y_test_inverse[:, i].max()], 'k--', lw=2)\n",
    "    axs[i // 2, i % 2].set_title(outputs_labels[i])\n",
    "    axs[i // 2, i % 2].set_xlabel('Actual')\n",
    "    axs[i // 2, i % 2].set_ylabel('Predicted')\n",
    "    axs[i // 2, i % 2].grid()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plotting percentage error\n",
    "fig, axs = plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "for i in range(4):\n",
    "    axs[i // 2, i % 2].scatter(Y_test_inverse[:, i], percentage_error[:, i])\n",
    "    axs[i // 2, i % 2].axhline(y=0, color='k', linestyle='--', lw=2)  # Line for 0% error\n",
    "    axs[i // 2, i % 2].set_title(f'Percentage Error for {outputs_labels[i]}')\n",
    "    axs[i // 2, i % 2].set_xlabel('Actual')\n",
    "    axs[i // 2, i % 2].set_ylabel('Percentage Error (%)')\n",
    "    axs[i // 2, i % 2].grid()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentage_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "isa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
